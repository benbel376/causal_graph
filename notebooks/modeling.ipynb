{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import Normalizer, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import sys\n",
    "from IPython.display import Image\n",
    "import copy\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import recall_score, f1_score, accuracy_score, precision_score\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix as con_mat\n",
    "from sklearn import metrics\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "import causalnex\n",
    "from causalnex.structure.notears import from_pandas\n",
    "from causalnex.plots import plot_structure, NODE_STYLE, EDGE_STYLE\n",
    "from causalnex.discretiser import Discretiser\n",
    "from causalnex.structure import DAGRegressor\n",
    "from causalnex.inference import InferenceEngine\n",
    "from causalnex.network import BayesianNetwork\n",
    "from causalnex.network.sklearn import BayesianNetworkClassifier\n",
    "from causalnex.discretiser.discretiser_strategy import (\n",
    "    DecisionTreeSupervisedDiscretiserMethod,\n",
    ")\n",
    "from causalnex.network import BayesianNetwork\n",
    "from causalnex.inference import InferenceEngine\n",
    "import mlflow\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(os.path.join('../scripts')))\n",
    "from utils import Utils\n",
    "Util = Utils(\"../logs/modeling_notebook.logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Dataset\n",
    "\n",
    "raw_df = pd.read_csv(\"../data/data.csv\")\n",
    "raw_df = raw_df.iloc[:,1:-1]\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating features and target\n",
    " \n",
    "features_df = raw_df.drop('diagnosis',axis=1)\n",
    "target_df = raw_df['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets eleminate highly correlated features first\n",
    "#correlation matrix\n",
    "Util.show_corr(features_df, \"correlation matrix of features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df2 = Util.remove_correlated(features_df, 0.9)\n",
    "features_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Util.forest_test(features_df2, target_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feat = Util.select_features_RFE(features_df2, target_df, 10)\n",
    "selected_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Util.forest_test(selected_feat, target_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "- As can be seen from the random forest regression test, the accuracy has decreased only by 1%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling and normalizing\n",
    "scaled = Util.scale_and_normalize(selected_feat)\n",
    "scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal Graph Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rejoin target and features\n",
    "pure_df = selected_feat.copy()\n",
    "pure_df[\"target\"] = LabelEncoder().fit_transform(target_df)\n",
    "\n",
    "# 1 means Malignunt and 0 means Benign \n",
    "pure_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = len(pure_df)/100\n",
    "pure_20 = pure_df.sample(int(20*factor), random_state=11)\n",
    "print(f\"size of pure_20 : {len(pure_20)}\")\n",
    "pure_40 = pure_df.sample(int(40*factor), random_state=11)\n",
    "print(f\"size of pure_40 : {len(pure_40)}\")\n",
    "pure_60 = pure_df.sample(int(60*factor), random_state=11)\n",
    "print(f\"size of pure_60 : {len(pure_60)}\")\n",
    "pure_80 = pure_df.sample(int(80*factor), random_state=11)\n",
    "print(f\"size of pure_80 : {len(pure_80)}\")\n",
    "print(f\"size of pure_100 : {len(pure_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the ground truth structure\n",
    "ground_truth = from_pandas(pure_df, tabu_parent_nodes=[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate structures from fractional datasets\n",
    "\n",
    "sm20 = from_pandas(pure_20, tabu_parent_nodes=[\"target\"])\n",
    "sm40 = from_pandas(pure_40, tabu_parent_nodes=[\"target\"])\n",
    "sm60 = from_pandas(pure_60, tabu_parent_nodes=[\"target\"])\n",
    "sm80 = from_pandas(pure_80, tabu_parent_nodes=[\"target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Stability of Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Util.plot_graph(ground_truth, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Util.jacc_index(ground_truth,sm20, 0.8, 0.8))\n",
    "Util.plot_graph(sm20, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Util.jacc_index(ground_truth,sm40, 0.8, 0.8))\n",
    "Util.plot_graph(sm40, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Util.jacc_index(ground_truth,sm60, 0.8, 0.8))\n",
    "Util.plot_graph(sm60, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Util.jacc_index(ground_truth,sm80, 0.8, 0.8))\n",
    "Util.plot_graph(sm80, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data and Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing data for logistic regression modelling\n",
    "original_x = selected_feat\n",
    "original_y = target_df.apply(lambda x: 0 if x==\"B\" else 1)\n",
    "original_full = original_x.copy()\n",
    "original_full[\"target\"] = original_y\n",
    "\n",
    "filtered = Util.filter_by_blanket(Util.apply_treshold(ground_truth, 0.8), original_x, \"target\")\n",
    "filtered_x = filtered[0]\n",
    "filtered_y = original_y\n",
    "filtered_full = filtered_x.copy()\n",
    "filtered_full[\"target\"] = filtered_y\n",
    "\n",
    "\n",
    "# preparing graphs for bayesian network modeling\n",
    "original_sm = Util.apply_treshold(ground_truth, 0.8)\n",
    "filtered_sm = filtered[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Network Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "desc_ori_df = Util.data_descretiser(original_full, original_x.columns.to_list(), \"target\")\n",
    "desc_filt_df = Util.data_descretiser(filtered_full, filtered_x.columns.to_list(), \"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset.\n",
    "train_o, test_o = train_test_split( desc_ori_df, train_size=0.8, test_size=0.2, random_state=27)\n",
    "train_f, test_f = train_test_split( desc_filt_df, train_size=0.8, test_size=0.2, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Bayesian Network\n",
    "bn1 = Util.get_bayesian_net(desc_ori_df, train_o, original_sm)\n",
    "bn2 = Util.get_bayesian_net(desc_filt_df, train_f, filtered_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_v1 = bn1.predict(test_o, 'target')\n",
    "true_v1 = test_o['target']\n",
    "\n",
    "pred_v2 = bn2.predict(test_f, 'target')\n",
    "true_v2 = test_f['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Recall: {:.4f}'.format(recall_score(y_true=true_v1, y_pred=pred_v1)))\n",
    "print('F1: {:.4f} '.format(f1_score(y_true=true_v1, y_pred=pred_v1)))\n",
    "print('Accuracy: {:.4f} '.format(accuracy_score(y_true=true_v1, y_pred=pred_v1)))\n",
    "print('Precision: {:.4f} '.format(precision_score(y_true=true_v1, y_pred=pred_v1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Recall: {:.4f}'.format(recall_score(y_true=true_v2, y_pred=pred_v2)))\n",
    "print('F1: {:.4f} '.format(f1_score(y_true=true_v2, y_pred=pred_v2)))\n",
    "print('Accuracy: {:.4f} '.format(accuracy_score(y_true=true_v2, y_pred=pred_v2)))\n",
    "print('Precision: {:.4f} '.format(precision_score(y_true=true_v2, y_pred=pred_v2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "- as can be seen from the above results the prediction ability of the data is the same\n",
    "  whether the nodes outside the blanket are included or not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training with the original dataset\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(original_x, original_y, test_size=0.2, random_state=0)\n",
    "log_model_o = LogisticRegression()\n",
    "log_model_o.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training with the filtered dataset\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(filtered_x, filtered_y, test_size=0.2, random_state=0)\n",
    "log_model_f = LogisticRegression()\n",
    "log_model_f.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_o = log_model_o.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.4f}'.format(log_model_o.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_f = log_model_f.predict(X_test2)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.4f}'.format(log_model_f.score(X_test2, y_test2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confustion matrix for ogininal dataset\n",
    "\n",
    "confusion_matrix = con_mat(y_test, y_pred_o)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confustion matrix for filtered dataset\n",
    "\n",
    "confusion_matrix = con_mat(y_test2, y_pred_f)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Util.get_metrics(y_true=y_test, y_pred=y_pred_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Util.get_metrics(y_true=y_test2, y_pred=y_pred_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "564a3f4a47946b61fadfbd8b0dd08da8476704ebae5691312144d394d4ce94ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
